{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll.base import scope\n",
    "import matplotlib.pyplot as plt   \n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, make_scorer, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. https://goo.gl/U2Uwz2\n",
    "# Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\n",
    "# 569 Rows and 30 features are used to train the model.\n",
    "df = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare our feature vector and target variables\n",
    "X = df.data\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train and test\n",
    "# train_test_split: Split arrays or matrices into random train and test subsets.\n",
    "# test_size: If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If train_size is also None, it will be set to 0.25.\n",
    "# random_state: Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we fit our training data to an XGBoost model using default hyperparameters. The performance of this model is reported via accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an XGBClassifier instance\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# Fit the training data to the XGBClassifier instance\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print our accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune parameters for one model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add a search space and tune the hyperparameters for the XGBoost model. We've chosen a subset of the hyperparameters available to tune. Hyperparameters can easily be added or removed from the search space. \n",
    "\n",
    "The search space is a dictionary. In that dictionary our keys are kyperparameters and our values are lists of possible values for that hyperparameter. We use hyperopt to assign values from the list of possible values for each hyperparameter. We use the scope method to ensure that the hyperparameter is assigned the correct datatype.\n",
    "\n",
    "Hyperopt's fmin method takes a search space, objective result, optimization algorithm, trials object, and number of iterations as input. It monitors the performance of each iteration (measured by the objective result) and returns the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize domain space for model types and parameters. \n",
    "\n",
    "# hp.choice(label, options) — Returns one of the options, which should be a list or tuple.\n",
    "# hp.randint(label, upper) — Returns a random integer between the range [0, upper).\n",
    "# hp.uniform(label, low, high) — Returns a value uniformly between low and high.\n",
    "# hp.quniform(label, low, high, q) — Returns a value round(uniform(low, high) / q) * q, i.e it rounds the decimal values and returns an integer.\n",
    "# hp.normal(label, mean, std) — Returns a real value that’s normally-distributed with mean and standard deviation sigma.\n",
    "\n",
    "search_space = {\n",
    "        'type': 'xgboost',\n",
    "        'colsample_bytree': scope.float(hp.uniform('colsample_bytree', 0.5, 1)),\n",
    "        'gamma' : hp.uniform('gamma', 1, 9),\n",
    "        'eta' : scope.float(hp.uniform('eta', 0.01, 0.99)),\n",
    "        'max_depth' : scope.int(hp.quniform(\"max_depth\", 2, 5, 1)),\n",
    "        'min_child_weight' : scope.int(hp.quniform('min_child_weight', 0, 10, 1)),\n",
    "        'n_estimators' : scope.int(hp.uniform('n_estimator', 1, 1250)), \n",
    "        'reg_alpha' : scope.int(hp.quniform('reg_alpha', 1, 200, 1)),\n",
    "        'reg_lambda' : scope.float(hp.uniform('reg_lambda', 0, 1)),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Custom objective function for hyperparameter tuning. Takes parameters and returns a score. The score is important because it is tracked by hyperopt and used to decide the next values for the hyperparameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : dict\n",
    "        Dictionary of parameters to be optimized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "    \"\"\"\n",
    "    \n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "\n",
    "    if classifier_type == 'svm':\n",
    "        clf = SVC(**params)\n",
    "    elif classifier_type == 'rf':\n",
    "        clf = RandomForestClassifier(**params)\n",
    "    elif classifier_type == 'logreg':\n",
    "        clf = LogisticRegression(**params)\n",
    "    elif classifier_type =='xgboost':\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Because fmin() tries to minimize the objective, this function must return the negative accuracy. \n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:11<00:00,  1.43s/trial, best loss: -0.9473684210526315]\n",
      "{'colsample_bytree': 0.5460980008186828, 'eta': 0.4254946349367153, 'gamma': 6.118914322780659, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 1153, 'reg_alpha': 184, 'reg_lambda': 0.4690120583032986, 'type': 'xgboost'}\n"
     ]
    }
   ],
   "source": [
    "# trials.trials - a list of dictionaries representing everything about the search\n",
    "# trials.results - a list of dictionaries returned by 'objective' during the search\n",
    "# trials.losses() - a list of losses (float for each 'ok' trial)\n",
    "# trials.statuses() - a list of status strings\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective, \n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials)\n",
    "\n",
    "best_params = hyperopt.space_eval(search_space, best_result)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best model/parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate several models at the same time. To do this we simply turn our search space into a list of dictionaries. Each dictionary is a model to evaluate. We can then use the trials object to track the performance of each model. The result tells us which model performed best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'svm',\n",
    "        'C': hp.lognormal('SVM_C', 0, 1.0),\n",
    "        'kernel': hp.choice('kernel', ['linear', 'rbf'])\n",
    "    },\n",
    "    {\n",
    "        'type': 'rf',\n",
    "        'criterion': hp.choice('criterion', ['gini', 'entropy'])\n",
    "    },\n",
    "    {\n",
    "        'type': 'logreg',\n",
    "        'C': hp.lognormal('LR_C', 0, 1.0),\n",
    "        'solver': hp.choice('solver', ['liblinear', 'lbfgs'])\n",
    "    },\n",
    "    {\n",
    "        'type': 'xgboost',\n",
    "        'colsample_bytree': scope.float(hp.uniform('colsample_bytree', 0.5, 1)),\n",
    "        'gamma' : hp.uniform('gamma', 1, 9),\n",
    "        'eta' : scope.float(hp.uniform('eta', 0.01, 0.99)),\n",
    "        'max_depth' : scope.int(hp.quniform(\"max_depth\", 2, 5, 1)),\n",
    "        'min_child_weight' : scope.int(hp.quniform('min_child_weight', 0, 10, 1)),\n",
    "        'n_estimators' : scope.int(hp.uniform('n_estimator', 1, 1250)), \n",
    "        'reg_alpha' : scope.int(hp.quniform('reg_alpha', 1, 200, 1)),\n",
    "        'reg_lambda' : scope.float(hp.uniform('reg_lambda', 0, 1)),\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Custom objective function for hyperparameter tuning. Takes parameters and returns a score.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : dict\n",
    "        Dictionary of parameters to be optimized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "    \"\"\"\n",
    "    \n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "\n",
    "    if classifier_type == 'svm':\n",
    "        clf = SVC(**params)\n",
    "    elif classifier_type == 'rf':\n",
    "        clf = RandomForestClassifier(**params)\n",
    "    elif classifier_type == 'logreg':\n",
    "        clf = LogisticRegression(**params)\n",
    "    elif classifier_type =='xgboost':\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "        \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Because fmin() tries to minimize the objective, this function must return the negative accuracy. \n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:22<00:00,  2.20trial/s, best loss: -0.9473684210526315]\n",
      "{'colsample_bytree': 0.5621100017085643, 'eta': 0.49590422470433626, 'gamma': 8.065737265073878, 'max_depth': 3, 'min_child_weight': 7, 'n_estimators': 466, 'reg_alpha': 179, 'reg_lambda': 0.010830699565542168, 'type': 'xgboost'}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective, \n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials)\n",
    "\n",
    "best_params = hyperopt.space_eval(search_space, best_result)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily change how we evaluate the model. Previously we simply clculated a mean accuracy. Now we will use cross validation. We can use the sklearn.model_selection.cross_val_score method to evaluate each combination of hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Custom objective function for hyperparameter tuning. Takes parameters and returns a score.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : dict\n",
    "        Dictionary of parameters to be optimized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "    \"\"\"\n",
    "    \n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "\n",
    "    if classifier_type == 'svm':\n",
    "        clf = SVC(**params)\n",
    "    elif classifier_type == 'rf':\n",
    "        clf = RandomForestClassifier(**params)\n",
    "    elif classifier_type == 'logreg':\n",
    "        clf = LogisticRegression(**params)\n",
    "    elif classifier_type =='xgboost':\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "        \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    accuracy = make_scorer(accuracy_score)\n",
    "    \n",
    "    performance = cross_val_score(clf, X_scaled, y, scoring=accuracy).mean()\n",
    "\n",
    "    # Because fmin() tries to minimize the objective, this function must return the negative accuracy. \n",
    "    return {'loss': -performance, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:58<00:00,  1.16s/trial, best loss: -0.9841950007762769]\n",
      "{'C': 0.34029464714571234, 'solver': 'liblinear', 'type': 'logreg'}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective, \n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials)\n",
    "\n",
    "best_params = hyperopt.space_eval(search_space, best_result)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change our performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can change which metric we use to evaluate performance. This is done by simply changing what performance metric is reported in our objective function. In the example below we switch from accuracy to recall. We could easily monitor other performance metrics like precision or f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \"\"\"\n",
    "    Custom objective function for hyperparameter tuning. Takes parameters and returns a score.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : dict\n",
    "        Dictionary of parameters to be optimized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "    \"\"\"\n",
    "    \n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "\n",
    "    if classifier_type == 'svm':\n",
    "        clf = SVC(**params)\n",
    "    elif classifier_type == 'rf':\n",
    "        clf = RandomForestClassifier(**params)\n",
    "    elif classifier_type == 'logreg':\n",
    "        clf = LogisticRegression(**params)\n",
    "    elif classifier_type =='xgboost':\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "        \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    recall = make_scorer(recall_score)\n",
    "    \n",
    "    performance = cross_val_score(clf, X_scaled, y, scoring=recall).mean()\n",
    "\n",
    "    # Because fmin() tries to minimize the objective, this function must return the negative accuracy. \n",
    "    return {'loss': -performance, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:13<02:34,  3.36s/trial, best loss: -0.9859154929577464]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-97d260b51b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     trials=trials)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0mtrials_save_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials_save_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         )\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mtrials_save_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials_save_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             )\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-84c5de367fcb>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Because fmin() tries to minimize the objective, this function must return the negative accuracy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     )\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         )\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m         )\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/one-super-repo/.venv/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1733\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1734\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1736\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective, \n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials)\n",
    "\n",
    "best_params = hyperopt.space_eval(search_space, best_result)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine our new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(params):\n",
    "    \n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "\n",
    "    if classifier_type == 'svm':\n",
    "        clf = SVC(**params)\n",
    "    elif classifier_type == 'rf':\n",
    "        clf = RandomForestClassifier(**params)\n",
    "    elif classifier_type == 'logreg':\n",
    "        clf = LogisticRegression(**params)\n",
    "    elif classifier_type =='xgboost':\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    return clf\n",
    "\n",
    "model = create_model(best_params)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# evaluate predictions\n",
    "print(\"F1 Score: \" + str(f1_score(y_test, y_pred, average='macro')))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
    "print(\"Recall: %.2f%%\" % (recall * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['malignant', 'benign']); ax.yaxis.set_ticklabels(['malignant', 'benign']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0db49d0eb7ca86137077693e1d91a66943fa1941c3f80e0d430ef5ec8b9452a4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
